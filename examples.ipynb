# %% [markdown]
# # Примеры использования модулей text_processor и text_analyzer

# %% [markdown]
# ## 1. Примеры работы с TextProcessor (ООП)

# %%
from text_processor import TextProcessor

# Создаем набор документов
documents = [
    "Машинное обучение это интересно и перспективно",
    "Глубокое обучение использует нейронные сети",
    "Нейронные сети применяются в машинном обучении",
    "Искусственный интеллект включает машинное обучение",
    "Глубокие нейронные сети - часть deep learning"
]

# %%
# Инициализируем процессор
processor = TextProcessor(documents)

# %% [markdown]
# ### Вычисляем TF (Term Frequency)

# %%
print("TF слова 'обучение' в документе 0:", processor.get_tf("обучение", 0))
print("TF слова 'нейронные' в документе 2:", processor.get_tf("нейронные", 2))

# %% [markdown]
# ### Вычисляем IDF (Inverse Document Frequency)

# %%
print("\nIDF слова 'обучение':", processor.get_idf("обучение"))
print("IDF слова 'нейронные':", processor.get_idf("нейронные"))
print("IDF слова 'искусственный':", processor.get_idf("искусственный"))

# %% [markdown]
# ### Вычисляем TF-IDF

# %%
print("\nTF-IDF слова 'обучение' в документе 0:", processor.get_tf_idf("обучение", 0))
print("TF-IDF слова 'сети' в документе 1:", processor.get_tf_idf("сети", 1))
print("TF-IDF стоп-слова 'и' в документе 0:", processor.get_tf_idf("и", 0))

# %% [markdown]
# ## 2. Примеры работы с text_analyzer (регулярные выражения)

# %%
from text_analyzer import process_ulysses, find_word_occurrences

# %%
# Загружаем и анализируем текст (предполагаем, что файл уже загружен в Colab)
text = """
Улисс - роман Джеймса Джойса. The novel Ulysses by James Joyce.
Улисс считается одним из самых сложных произведений. The novel is complex.
Улисс был опубликован в 1922 году. Ulysses was published in 1922.
"""

# Сохраняем текст во временный файл для демонстрации
with open('ulysses_sample.txt', 'w', encoding='utf-8') as f:
    f.write(text)

# %%
# Анализируем текст
processed_text = process_ulysses('ulysses_sample.txt')

# %%
# Ищем вхождения слова "Улисс" с контекстом
if processed_text:
    print("\nПоиск вхождений слова 'Улисс':")
    find_word_occurrences(
        text=processed_text,
        target_word="Улисс",
        left_len=3,
        right_len=3,
        cut_length=True
    )

# %%
# Ищем вхождения слова "novel" с контекстом
if processed_text:
    print("\nПоиск вхождений слова 'novel':")
    find_word_occurrences(
        text=processed_text,
        target_word="novel",
        left_len=2,
        right_len=4,
        cut_length=False
    )

# %% [markdown]
# ## 3. Комбинированный пример

# %%
# Используем TextProcessor для анализа результатов text_analyzer
if processed_text:
    # Создаем документы из найденных вхождений
    occurrences = find_word_occurrences(processed_text, "Улисс", 2, 2)
    
    if occurrences:
        print("\nАнализ TF-IDF для найденных вхождений:")
        occurrence_processor = TextProcessor(occurrences)
        
        print("TF-IDF слова 'Джеймса' в первом вхождении:", 
              occurrence_processor.get_tf_idf("Джеймса", 0))
        print("TF-IDF слова 'произведений' во втором вхождении:", 
              occurrence_processor.get_tf_idf("произведений", 1))
